{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "complete_neural_net_with_Keras.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n34nHA0HfYBh",
        "outputId": "13b4893e-a644-4f52-a58a-4d885f9b42f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# CIFAR-10 Dataset has 60000 images of 32x32 with 3 color channels, 10 classes.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "\n",
        "from pathlib import Path"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NT7TPVCXusi2",
        "outputId": "577d3ffa-e41c-4d18-f7e8-577d29a462e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "X_train.shape, y_train.shape, X_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 11s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 32, 32, 3), (50000, 1), (10000, 32, 32, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mHCfmRscvD01",
        "outputId": "49f74397-bc95-44ac-a0f7-439583edffa1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# Normalize data set to 0-to-1 range for pixel value [0...255].\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "\n",
        "num_labels = len(np.unique(y_test))\n",
        "# Convert class vectors to binary class matrices: labels from 0 to 9 to matrix \n",
        "# where each label will be array with on element set to 1 and the rest set to 0.\n",
        "y_train = keras.utils.to_categorical(y_train, num_labels)\n",
        "y_test = keras.utils.to_categorical(y_test, num_labels)\n",
        "print(X_train.max())\n",
        "y_train.shape, y_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 10), (10000, 10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FqJgrObECPz4"
      },
      "source": [
        "Create a model and add layers:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dyXpm2arzToX",
        "outputId": "35cee485-2cab-433d-f96e-abae6a92d31b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        }
      },
      "source": [
        "size_px = 32\n",
        "ncolors = 3\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Analyze 3x3 tiles and add padding pixels to tile: \"same\".\n",
        "model.add(Conv2D(32, (3,3), padding='same', activation='relu',\n",
        "                 input_shape=(size_px,size_px,ncolors)))\n",
        "model.add(Conv2D(32, (3,3), activation='relu'))\n",
        "# Keep only significant parts.\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "# Regularization by cutting some random connections between layers.\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
        "model.add(Conv2D(64, (3,3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Flatten the input from 2D shape.\n",
        "model.add(Flatten())\n",
        "\n",
        "# Regularization by cutting some random connections between layers.\n",
        "model.add(Dropout(0.01))\n",
        "\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_labels, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,250,858\n",
            "Trainable params: 1,250,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LnOMYjsc44L4",
        "colab": {}
      },
      "source": [
        "# Compile the model with Adaptive Moment Estimation.\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p-wsryxwBn9-",
        "outputId": "18d6efd6-bfd6-404a-a634-b796aad2f6d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        }
      },
      "source": [
        "# This take 1 hour on CPU!!!\n",
        "\n",
        "%%time\n",
        "# Wall time: 1h 16min 1s    in Google Colab.\n",
        "model.fit(X_train, y_train, batch_size=64, epochs=20,\n",
        "          validation_data=(X_test, y_test), shuffle=True)\n",
        "\n",
        "print('Saving model...')\n",
        "with Path('model_structure.json') as out:\n",
        "    out.write_text(model.to_json())\n",
        "\n",
        "print('Saving weights...')\n",
        "model.save_weights('model_weights.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "50000/50000 [==============================] - 228s 5ms/step - loss: 1.2405 - accuracy: 0.5563 - val_loss: 1.0150 - val_accuracy: 0.6394\n",
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 230s 5ms/step - loss: 1.0281 - accuracy: 0.6359 - val_loss: 0.9112 - val_accuracy: 0.6765\n",
            "Epoch 3/20\n",
            "50000/50000 [==============================] - 230s 5ms/step - loss: 0.8948 - accuracy: 0.6844 - val_loss: 0.7903 - val_accuracy: 0.7239\n",
            "Epoch 4/20\n",
            "50000/50000 [==============================] - 229s 5ms/step - loss: 0.8145 - accuracy: 0.7131 - val_loss: 0.7373 - val_accuracy: 0.7412\n",
            "Epoch 5/20\n",
            "50000/50000 [==============================] - 230s 5ms/step - loss: 0.7571 - accuracy: 0.7344 - val_loss: 0.7106 - val_accuracy: 0.7505\n",
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 230s 5ms/step - loss: 0.7101 - accuracy: 0.7513 - val_loss: 0.7010 - val_accuracy: 0.7610\n",
            "Epoch 7/20\n",
            "50000/50000 [==============================] - 230s 5ms/step - loss: 0.6615 - accuracy: 0.7657 - val_loss: 0.6589 - val_accuracy: 0.7710\n",
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 228s 5ms/step - loss: 0.6355 - accuracy: 0.7760 - val_loss: 0.6654 - val_accuracy: 0.7747\n",
            "Epoch 9/20\n",
            "50000/50000 [==============================] - 228s 5ms/step - loss: 0.6048 - accuracy: 0.7873 - val_loss: 0.6564 - val_accuracy: 0.7760\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - 227s 5ms/step - loss: 0.5698 - accuracy: 0.7985 - val_loss: 0.6371 - val_accuracy: 0.7820\n",
            "Epoch 11/20\n",
            "50000/50000 [==============================] - 226s 5ms/step - loss: 0.5545 - accuracy: 0.8054 - val_loss: 0.6186 - val_accuracy: 0.7925\n",
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 226s 5ms/step - loss: 0.5324 - accuracy: 0.8113 - val_loss: 0.6152 - val_accuracy: 0.7868\n",
            "Epoch 13/20\n",
            "50000/50000 [==============================] - 227s 5ms/step - loss: 0.5140 - accuracy: 0.8192 - val_loss: 0.6190 - val_accuracy: 0.7895\n",
            "Epoch 14/20\n",
            "50000/50000 [==============================] - 227s 5ms/step - loss: 0.4945 - accuracy: 0.8250 - val_loss: 0.6375 - val_accuracy: 0.7891\n",
            "Epoch 15/20\n",
            "50000/50000 [==============================] - 227s 5ms/step - loss: 0.4844 - accuracy: 0.8286 - val_loss: 0.6392 - val_accuracy: 0.7870\n",
            "Epoch 16/20\n",
            "50000/50000 [==============================] - 227s 5ms/step - loss: 0.4649 - accuracy: 0.8350 - val_loss: 0.6343 - val_accuracy: 0.7915\n",
            "Epoch 17/20\n",
            "50000/50000 [==============================] - 229s 5ms/step - loss: 0.4546 - accuracy: 0.8387 - val_loss: 0.6115 - val_accuracy: 0.7963\n",
            "Epoch 18/20\n",
            "50000/50000 [==============================] - 228s 5ms/step - loss: 0.4388 - accuracy: 0.8442 - val_loss: 0.6066 - val_accuracy: 0.8002\n",
            "Epoch 19/20\n",
            "50000/50000 [==============================] - 229s 5ms/step - loss: 0.4345 - accuracy: 0.8462 - val_loss: 0.6349 - val_accuracy: 0.7925\n",
            "Epoch 20/20\n",
            "50000/50000 [==============================] - 227s 5ms/step - loss: 0.4289 - accuracy: 0.8488 - val_loss: 0.6140 - val_accuracy: 0.7953\n",
            "Saving model...\n",
            "Saving weights...\n",
            "CPU times: user 2h 20min 37s, sys: 3min 14s, total: 2h 23min 52s\n",
            "Wall time: 1h 16min 1s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r-l_gQ7pYS6Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "a475daa6-c4b7-418b-c412-f894a9912543"
      },
      "source": [
        "from keras.models import model_from_json\n",
        "\n",
        "# These are the CIFAR10 class labels from the training data (from 0 to 9).\n",
        "class_labels = [\n",
        "    \"Plane\",\n",
        "    \"Car\",\n",
        "    \"Bird\",\n",
        "    \"Cat\",\n",
        "    \"Deer\",\n",
        "    \"Dog\",\n",
        "    \"Frog\",\n",
        "    \"Horse\",\n",
        "    \"Boat\",\n",
        "    \"Truck\"\n",
        "]\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd '/gdrive/My Drive/Colab Notebooks'\n",
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive/My Drive/Colab Notebooks\n",
            "Autograd.ipynb\n",
            "Autograd_with_tensors.ipynb\n",
            "car.png\n",
            "cat.png\n",
            "complete_neural_net_with_Keras.ipynb\n",
            "CPU_to_GPU.ipynb\n",
            "frog.png\n",
            "model_structure.json\n",
            "model_weights.h5\n",
            "PyTorch_FMNIST_Fashion_dataset_predicting.ipynb\n",
            "PyTorch_Playground.ipynb\n",
            "PyTorch_Tensors.ipynb\n",
            "Troubleshooting.ipynb\n",
            "Using_Optimizers.ipynb\n",
            "Validation.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siLO4wJl_QrN",
        "colab_type": "code",
        "outputId": "8d33279a-c348-4334-c1ca-f83e1ff31ea8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        }
      },
      "source": [
        "# Load the json file that contains the model's structure.\n",
        "f = Path('model_structure.json')\n",
        "model_structure = f.read_text()\n",
        "# Recreate the Keras model object from the json data.\n",
        "model = model_from_json(model_structure)\n",
        "\n",
        "# Re-load the model's trained weights.\n",
        "model.load_weights('model_weights.h5')\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_21 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 13, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,250,858\n",
            "Trainable params: 1,250,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zA_dIkhWFQV3",
        "outputId": "e36aa013-450e-44b8-9681-5c67bdd02d74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from keras.preprocessing import image\n",
        "\n",
        "# Load an image file to test, resizing it to 32x32 pixels (required by the model)\n",
        "img = image.load_img('frog.png', target_size=(32, 32))\n",
        "\n",
        "# Convert the image to a numpy array.\n",
        "image_to_test = image.img_to_array(img) / 255\n",
        "\n",
        "# Add a fourth dimension to the image (since Keras expects a list of images, not a single image)\n",
        "images_lst = np.expand_dims(image_to_test, axis=0)\n",
        "\n",
        "# Make a prediction using the model.\n",
        "preds = model.predict(images_lst)\n",
        "\n",
        "# Since we are only testing one image, we only need to check the first result.\n",
        "single_pred = preds[0]\n",
        "\n",
        "# We will get a likelihood score for all 10 possible classes. Find out which class had the highest score.\n",
        "max_prob_class_idx = int(np.argmax(single_pred))\n",
        "class_likelihood = single_pred[max_prob_class_idx]\n",
        "\n",
        "# Get the name of the most likely class.\n",
        "class_label = class_labels[max_prob_class_idx]\n",
        "\n",
        "print('This is image is a {} - Likelihood: {:2f}'.format(class_label, class_likelihood))\n",
        "# This is image is a Cat - Likelihood: 0.980386\n",
        "# This is image is a Car - Likelihood: 0.902425\n",
        "# This is image is a Bird - Likelihood: 0.350181    # 20 epochs are not enough, 30 can do the job"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is image is a Bird - Likelihood: 0.350181\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wn-R52JYQTp6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "29dc9e76-d3d1-45fa-ffef-8b7ad60ce202"
      },
      "source": [
        "from keras.applications import vgg16\n",
        "\n",
        "# Load Keras' VGG16 model that was pre-trained against the ImageNet database.\n",
        "model = vgg16.VGG16()\n",
        "\n",
        "# Load the image file, resizing it to 224x224 pixels (required by this model).\n",
        "img = image.load_img('bay.jpg', target_size=(224, 224))\n",
        "\n",
        "# Convert the image to a numpy array and add a fourth dimension.\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "\n",
        "# Normalize the input image's pixel values to the range used when training the neural network.\n",
        "x = vgg16.preprocess_input(x)\n",
        "\n",
        "# Run the image through the deep neural network to make a prediction\n",
        "preds = model.predict(x)\n",
        "print(preds.shape)\n",
        "preds[0][:3]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 1000)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7.7008048e-07, 2.2140763e-07, 2.1741250e-06], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGIkWUHkSItH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "683c2dd3-78df-45ef-ecbd-4c384abaf349"
      },
      "source": [
        "# Look up the names of the predicted classes. Index zero is the results for the first image.\n",
        "predicted_classes = vgg16.decode_predictions(preds)\n",
        "\n",
        "print('Top predictions for this image:')\n",
        "\n",
        "for _imagenet_id, name, likelihood in predicted_classes[0]:\n",
        "    print('Prediction: {} - {:2f}'.format(name, likelihood))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
            "40960/35363 [==================================] - 0s 0us/step\n",
            "Top predictions for this image:\n",
            "Prediction: seashore - 0.395213\n",
            "Prediction: promontory - 0.326128\n",
            "Prediction: lakeside - 0.119613\n",
            "Prediction: breakwater - 0.062801\n",
            "Prediction: sandbar - 0.045267\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEDkYLS2Scgb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}